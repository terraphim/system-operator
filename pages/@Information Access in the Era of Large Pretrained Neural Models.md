date:: [[Thu, 27.04.2023]]
running-time:: 1:04:45
title:: @Information Access in the Era of Large Pretrained Neural Models
item-type:: [[videoRecording]]
access-date:: 2023-05-08T07:40:25Z
original-title:: Information Access in the Era of Large Pretrained Neural Models
url:: https://www.youtube.com/watch?v=IvEhA4x_RWA
library-catalog:: YouTube
links:: [Local library](zotero://select/library/items/XYZKW9YL), [Web library](https://www.zotero.org/users/6520516/items/XYZKW9YL)

- [[Abstract]]
	- Information access – the challenge of connecting users to previously stored information that is relevant to their needs – dates back millennia. The technologies have changed – from clay tablets stacked in granaries to books on shelves arranged according to the Dewey Decimal Classification to digital content indexed by web search engines – but the aims have not. Large pretrained neural models such as BERT, GPT-3, and most recently, ChatGPT, represent the latest innovations that can help tackle this challenge.
	  
	  Undoubtedly, these models have already had significant impact, but of late, the hype surrounding the latest iterations in my opinion is overblown. In this talk, Professor Jimmy Lin will offer my perspectives on the future of information access in light of these large pretrained neural models. He will discuss representation learning and different architectures for retrieval, reranking, and information synthesis. Looking backwards historically, it’ll become clear that the vision of effortlessly connecting users to relevant information has not changed, although the tools at our disposal have very much so, creating both tremendous opportunities and as well as challenges.
	  
	  #EAISeminars #AISeminar #AIWebinar #AIexpert #artificialintelligence